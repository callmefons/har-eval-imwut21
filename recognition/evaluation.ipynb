{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libralies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "print(\"Current working dir : %s\" % os.getcwd())\n",
    "import pandas as pd\n",
    "import joblib # save/load models\n",
    "import pickle # save/load features\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, classification_report, accuracy_score, balanced_accuracy_score, confusion_matrix\n",
    "from scipy import interp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions used for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    \n",
    "    df = df.dropna()\n",
    "    \n",
    "    # remove a class has samples < 2\n",
    "    for i in df.act.unique():\n",
    "        if(df[df['act'] == i][\"index\"].count()<2):\n",
    "            print(df[df['act']==i].act)\n",
    "            indexNames = df[df['act'] == i].index\n",
    "            df.drop(indexNames , inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weight(y_train):\n",
    "    # estimate sample weights by class for unbalanced datasets.\n",
    "    class_weight = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(n_classes):\n",
    "    # define model\n",
    "    mcl = XGBClassifier(\n",
    "                        num_class=n_classes,\n",
    "                        objective='multi:softprob')\n",
    "    return mcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid_searchCV(model):\n",
    "    param_grid = {\n",
    "          'max_depth':[4,5,6],\n",
    "          'min_child_weight':[4,5,6],\n",
    "          'early_stopping_rounds': [10],\n",
    "          'scale_pos_weight' :[1],\n",
    "         }\n",
    "        \n",
    "    # define grid search\n",
    "    # n_jobs=-1 is a standard of CPU cores to train our model.\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1 , cv=10)\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    from sklearn import preprocessing\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    preprocessing.LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictions(y_test, predictions):\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test, predictions)\n",
    "    print(\"balanced_accuracy: %.2f%%\" % (balanced_accuracy * 100.0))\n",
    "\n",
    "    roc_auc_score = multiclass_roc_auc_score(y_test, predictions)\n",
    "    print(\"roc_auc_score: %.2f%%\" % (roc_auc_score * 100.0))\n",
    "\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model by each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create users bases on user_id in the database\n",
    "users = [i for i in range(112,185,1)] # 40 \n",
    "# users = [i for i in range(203,258,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in users:\n",
    "    \n",
    "    print(\"------------------------\", user, \"------------------------\")\n",
    "    \n",
    "    # read data from a defined user\n",
    "    user_id = user\n",
    "    data = pd.read_csv(\"users-feats/train_data_imwut20_\"+str(user_id)+\".csv\");\n",
    "    data.time = pd.to_datetime(data.time)\n",
    "    data = data.reset_index()\n",
    "    data[\"index\"].count()\n",
    "    \n",
    "    # create dataframe\n",
    "    df = data\n",
    "    \n",
    "    # preprocessing\n",
    "    df = preprocessing(df)\n",
    "    \n",
    "    class_names = df.act.unique()\n",
    "    n_classes = len(df.act.unique())\n",
    "    \n",
    "    print(\"act classes: \", df.act.unique())\n",
    "    print(\"number of classes: \", len(df.act.unique()))\n",
    "    \n",
    "    X = df.iloc[:,2:14]\n",
    "    y = df.act\n",
    "    \n",
    "    print(\"X shape: \", X.shape)\n",
    "    print(\"y shape: \", y.shape)\n",
    "    from collections import Counter\n",
    "    counter = Counter(y)\n",
    "    counter[1]\n",
    "\n",
    "    # shuffle and split training and test sets\n",
    "    random_state = 42\n",
    "    training_features, test_features, training_target, test_target = train_test_split(X, y, test_size=.1, random_state=random_state)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(training_features, training_target, test_size=.1, random_state=random_state)\n",
    "\n",
    "    # create evaluation dataset\n",
    "    eval_set = [(X_val, y_val)]\n",
    "    \n",
    "    # calculate class_weight\n",
    "    class_weight = calculate_class_weight(y_train)\n",
    "       \n",
    "    # create model\n",
    "    mcl = create_model(n_classes)\n",
    "    \n",
    "    # gridsearchCV\n",
    "    mcl = create_grid_searchCV(mcl)\n",
    "        \n",
    "    # fit parameters\n",
    "    fit_params={\"sample_weight\": class_weight, \"eval_set\": eval_set, \"verbose\":False}\n",
    "\n",
    "    mcl.fit(X_train, y_train, **fit_params)\n",
    "\n",
    "    y_pred = mcl.best_estimator_.predict(test_features)\n",
    "    #y_pred = mcl.predict(test_features)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    \n",
    "    #eval\n",
    "    evaluate_predictions(test_target, predictions)\n",
    "    \n",
    "    # save the model to disk\n",
    "    filename = \"users-models/model_user_\"+str(user_id)+\".sav\"\n",
    "    joblib.dump(mcl, filename)\n",
    "    \n",
    "    # Saving the objects:\n",
    "    filename_objs = \"users-models/model_user_\"+str(user_id)+\".pkl\"\n",
    "    \n",
    "    with open(filename_objs, 'wb') as f:\n",
    "        pickle.dump([training_features, test_features, training_target, test_target,\n",
    "                     X_train, X_val, y_train, y_val,\n",
    "                     class_weight,class_names,n_classes], f)\n",
    "        \n",
    "    print(\"------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
